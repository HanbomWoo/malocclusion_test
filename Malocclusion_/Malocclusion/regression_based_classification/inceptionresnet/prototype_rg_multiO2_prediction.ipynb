{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Model\n",
    "---\n",
    "\n",
    "* Regression\n",
    "* 2009 data로 class1,2,3 10fold\n",
    "\n",
    "\n",
    "https://docs.google.com/presentation/d/1cI3teBcQoGBhfrdVrv9rnM4jHGaPToDS7Zh7t0q7GKg/edit#slide=id.g97e66187c6_0_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed as random_seed\n",
    "random_seed(50)\n",
    "from numpy.random import seed as np_random_seed\n",
    "np_random_seed(50)\n",
    "\n",
    "tf.random.set_seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/whbom/Malocclusion/bom_regression/model/inceptionresnet',\n",
       " '/root/miniconda3/lib/python37.zip',\n",
       " '/root/miniconda3/lib/python3.7',\n",
       " '/root/miniconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/root/miniconda3/lib/python3.7/site-packages',\n",
       " '/root/miniconda3/lib/python3.7/site-packages/locket-0.2.1-py3.7.egg',\n",
       " '/root/miniconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '/docker_mnt/data5/jin/jin/python/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.sys.path.append(r'/docker_mnt/data5/jin/jin/python/')\n",
    "\n",
    "os.sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2978313750507894698]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=0\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=0\n",
    "from random import seed as random_seed\n",
    "random_seed(42)\n",
    "from numpy.random import seed as np_random_seed\n",
    "np_random_seed(42)\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Data Science\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations, initializers, regularizers, optimizers, losses, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_type = 'so_rl'\n",
    "\n",
    "input_path_root = r'../../../data/reprocess_data/fullRange_D'\n",
    "\n",
    "loss_param=0.5\n",
    "MODEL_TYPE=\"prototype\"\n",
    "version=\"v1\"\n",
    "\n",
    "# <model 저장>\n",
    "# output_path_root = r'../results/'\n",
    "output_path_root = f'../../results/multiout/{MODEL_TYPE}/{loss_param}_full_range_1951_multiO2/{version}'\n",
    "output_path = os.path.join(output_path_root,  so_type)\n",
    "output_path_weight = os.path.join(output_path, r'weights/')\n",
    "\n",
    "try:\n",
    "    os.makedirs(output_path_weight) \n",
    "    \n",
    "except FileExistsError as err:      \n",
    "    print(err)\n",
    "# else:\n",
    "#     print(output_path)\n",
    "#     print(output_path_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../data/reprocess_data/fullRange_D'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../results/multiout/prototype/0.5_full_range_1951_multiO2/v1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "---\n",
    "- Class 0 : 분별하기 어려운 data (65 sample) -> 제외\n",
    "\n",
    "- Class 3 : 하악이 상악보다 앞으로 돌출된 경우 (1136 sample) -> -1.0\n",
    "- Class 1 : 상하악의 맞물림 상태는 정상이지만 치열이 고르지 않은 경우 (1707 sample) -> 0.0\n",
    "- Class 2 : 상악이 하악보다 앞으로 돌출된 경우 (1175 sample) -> 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_class2reg(label_df):\n",
    "    label_r = np.copy(label_df.angle_class_r)\n",
    "    label_df.loc[label_r == 1, 'angle_class_r'] = 0\n",
    "    label_df.loc[label_r == 2, 'angle_class_r'] = 1\n",
    "    label_df.loc[label_r == 3, 'angle_class_r'] = -1\n",
    "    \n",
    "    label_l = np.copy(label_df.angle_class_l)\n",
    "    label_df.loc[label_l == 1, 'angle_class_l'] = 0\n",
    "    label_df.loc[label_l == 2, 'angle_class_l'] = 1\n",
    "    label_df.loc[label_l == 3, 'angle_class_l'] = -1\n",
    "    \n",
    "    return label_df\n",
    "\n",
    "def generate_data_by_patient(x, y): #y_distance):\n",
    "    if x.shape[-1] == 12:\n",
    "        x = np.concatenate([x[..., :3], x[..., 3:6], x[..., 6:9], x[..., 9:]]) \n",
    "        y = np.concatenate([y[:, 0], y[:, 1], y[:, 2], y[:, 3]])\n",
    "    elif x.shape[-1] == 6:\n",
    "        x = np.concatenate([x[..., :3], x[..., 3:]]) # Right side,Left side !!!\n",
    "        \n",
    "        y_r_test= to_categorical(y[:,0], num_classes=3)\n",
    "        y_l_test= to_categorical(y[:,1], num_classes=3)\n",
    "        \n",
    "        y = np.concatenate([y[:, 0], y[:, 1]])\n",
    "        y_onehot=np.concatenate((y_r_test,y_l_test),axis=0)\n",
    "        \n",
    "#         y_distance = np.concatenate([y_distance[:, 0], y_distance[:, 1]])\n",
    "    \n",
    "    return x, y, y_onehot #, y_distance\n",
    "\n",
    "# def generate_info_df_by_patient(info_df):\n",
    "#     info_df_r = info_df.copy()\n",
    "#     for row_idx, info in enumerate(info_df_r['info']):\n",
    "#         info_df_r.iloc[row_idx] = info + '_r'\n",
    "        \n",
    "#     info_df_l = info_df.copy()\n",
    "#     for row_idx, info in enumerate(info_df_l['info']):\n",
    "#         info_df_l.iloc[row_idx] = info + '_l'\n",
    "    \n",
    "#     info_df = pd.concat((info_df_r, info_df_l), ignore_index=True)\n",
    "#     del info_df_r, info_df_l\n",
    "    \n",
    "#     info_df1 = info_df.copy()\n",
    "        \n",
    "#     info_df2 = info_df.copy()\n",
    "#     for row_idx, info in enumerate(info_df2['info']):\n",
    "#         info_df2.iloc[row_idx] = info.replace('01A1', '02B1')\n",
    "    \n",
    "#     info_df = pd.concat((info_df1, info_df2), ignore_index=True)\n",
    "#     del info_df1, info_df2\n",
    "\n",
    "#     return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0769970bb45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_input' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.load(os.path.join(input_path_root, f'fullRange_D.npy'))\n",
    "label_df = pd.read_csv(os.path.join(input_path_root, f'fullRange_D.csv'))\n",
    "label_df = convert_label_class2reg(label_df)\n",
    "\n",
    "y = label_df.loc[:, ['angle_class_r', 'angle_class_l']].to_numpy()\n",
    "y_distance= label_df.loc[:, ['distance(r)', 'distance(l)']].to_numpy()\n",
    "\n",
    "y_distance = y_distance.astype(np.float32)\n",
    "\n",
    "print(x.max())\n",
    "x=preprocess_input(x)\n",
    "print(x.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------onehot function test------------------\n",
    "x_tt, y_tt, y_onehot_tt=generate_data_by_patient(x,y)\n",
    "\n",
    "y_onehot_tt_r=y_onehot_tt[:(y_onehot_tt.shape[0]//2)]\n",
    "y_onehot_tt_l=y_onehot_tt[(y_onehot_tt.shape[0]//2):]\n",
    "\n",
    "y_onehot_tt_r=list(y_onehot_tt_r)\n",
    "y_onehot_tt_l=list(y_onehot_tt_l)\n",
    "\n",
    "\n",
    "label_df[\"one-hot-r\"]=y_onehot_tt_r\n",
    "label_df[\"one-hot-l\"]=y_onehot_tt_l\n",
    "label_df\n",
    "#---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dtype, x.shape)\n",
    "print(y.dtype, y.shape)\n",
    "print()\n",
    "display.display(label_df.info())\n",
    "display.display(label_df)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure()\n",
    "\n",
    "plt.title('Label')\n",
    "sns.countplot(np.concatenate([label_df.angle_class_r, label_df.angle_class_l]))\n",
    "\n",
    "plt.show()\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = np.concatenate([label_df.angle_class_r, label_df.angle_class_l])\n",
    "\n",
    "\n",
    "print(\"calss -1:\",len(cnt[cnt==-1]))\n",
    "print(\"calss 0:\",len(cnt[cnt==0]))\n",
    "print(\"calss 1:\",len(cnt[cnt==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = InceptionResNetV2(include_top=False, weights=None, input_shape=(None, None, 3))\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='gap')(x)\n",
    "    x = layers.Dense(256, activation='relu', name='dense')(x)\n",
    "    x = layers.Dropout(0.2, name='dropout')(x)\n",
    "    \n",
    "    one_hot_prediction=layers.Dense(3, activation='softmax', name='classification')(x)\n",
    "\n",
    "    \n",
    "    model = models.Model(inputs=base_model.input, outputs=[regression_prediction,one_hot_prediction])\n",
    "#     model = models.Model(inputs=base_model.input, outputs=[regression_prediction,one_hot_prediction,distance_prediction])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold CV: 06/10\n",
      "[  10   30   45   55   61   62   82   85  107  110  111  118  119  126\n",
      "  131  137  143  144  156  160  179  188  195  202  231  232  240  246\n",
      "  252  272  279  292  295  305  317  318  323  329  341  343  368  374\n",
      "  379  394  396  400  403  408  409  426  428  437  447  456  488  500\n",
      "  507  510  511  516  517  540  543  552  560  568  577  586  608  612\n",
      "  615  629  659  663  670  686  693  739  742  798  808  815  824  829\n",
      "  830  831  841  845  849  852  859  877  915  918  966  968  970  978\n",
      "  990 1005 1038 1044 1045 1062 1071 1072 1088 1105 1113 1115 1120 1130\n",
      " 1137 1139 1141 1146 1151 1154 1171 1186 1195 1200 1205 1210 1243 1259\n",
      " 1263 1266 1269 1280 1288 1292 1297 1301 1306 1350 1356 1358 1369 1398\n",
      " 1402 1409 1432 1436 1447 1473 1479 1480 1514 1515 1534 1536 1539 1550\n",
      " 1570 1616 1617 1646 1654 1657 1675 1682 1695 1701 1708 1721 1725 1728\n",
      " 1729 1733 1738 1758 1759 1765 1769 1787 1801 1803 1812 1830 1839 1842\n",
      " 1843 1844 1860 1866 1869 1885 1888 1921 1924 1942 1945 1948 1956 1970\n",
      " 1987 1990 1995 2003 2007]\n",
      "Train on 2892 samples, validate on 724 samples\n",
      "Epoch 1/100\n",
      "2892/2892 [==============================] - 210s 73ms/sample - loss: 1.7206 - regression_prediction_loss: 0.6180 - classification_loss: 1.1028 - regression_prediction_acc: 0.4302 - regression_prediction_mae: 0.6179 - classification_acc: 0.4236 - classification_mae: 0.4414 - val_loss: 1.6544 - val_regression_prediction_loss: 0.5804 - val_classification_loss: 1.0751 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5795 - val_classification_acc: 0.4503 - val_classification_mae: 0.4376\n",
      "Epoch 2/100\n",
      "2892/2892 [==============================] - 187s 65ms/sample - loss: 1.5926 - regression_prediction_loss: 0.5334 - classification_loss: 1.0582 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5342 - classification_acc: 0.4948 - classification_mae: 0.4316 - val_loss: 2.2636 - val_regression_prediction_loss: 1.0050 - val_classification_loss: 1.2595 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 1.0036 - val_classification_acc: 0.2928 - val_classification_mae: 0.4572\n",
      "Epoch 3/100\n",
      "2892/2892 [==============================] - 185s 64ms/sample - loss: 1.6512 - regression_prediction_loss: 0.5722 - classification_loss: 1.0788 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5723 - classification_acc: 0.4302 - classification_mae: 0.4354 - val_loss: 1.6686 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0846 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4369\n",
      "Epoch 4/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5702 - classification_loss: 1.0786 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6693 - val_regression_prediction_loss: 0.5859 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5850 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 5/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6443 - regression_prediction_loss: 0.5686 - classification_loss: 1.0756 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5687 - classification_acc: 0.4357 - classification_mae: 0.4346 - val_loss: 1.8457 - val_regression_prediction_loss: 0.7406 - val_classification_loss: 1.1062 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.7396 - val_classification_acc: 0.3301 - val_classification_mae: 0.4450\n",
      "Epoch 6/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 7/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 8/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 9/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4353 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 10/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 11/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5695 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6693 - val_regression_prediction_loss: 0.5857 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5848 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 12/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6692 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 13/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 14/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5689 - classification_loss: 1.0780 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 15/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 16/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 17/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0786 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4362\n",
      "Epoch 18/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 19/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 20/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 21/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 22/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 23/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5693 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4353 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 24/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5692 - classification_loss: 1.0780 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 25/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5693 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 26/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 27/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 28/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 29/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 30/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6695 - val_regression_prediction_loss: 0.5859 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5850 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 31/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 32/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 33/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 34/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 35/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 36/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 37/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 38/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 39/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 40/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5697 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 41/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 42/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 43/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5695 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 44/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 45/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 46/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 47/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4346 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 48/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6696 - val_regression_prediction_loss: 0.5860 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5851 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 49/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 50/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 51/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5697 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 52/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 53/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 54/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 55/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5697 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 56/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 57/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 58/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 59/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 60/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5693 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 61/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5702 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 62/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 63/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6694 - val_regression_prediction_loss: 0.5859 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5850 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 64/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 65/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 66/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 67/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 68/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5689 - classification_loss: 1.0779 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 69/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 70/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 71/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6686 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0846 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4367\n",
      "Epoch 72/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 73/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4356 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 74/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 75/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 76/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 77/100\n",
      "2888/2892 [============================>.] - ETA: 0s - loss: 1.6476 - regression_prediction_loss: 0.5694 - classification_loss: 1.0782 - regression_prediction_acc: 0.4307 - regression_prediction_mae: 0.5694 - classification_acc: 0.4307 - classification_mae: 0.4349"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mmake_logs\u001b[0;34m(model, logs, outputs, mode, prefix)\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0;34m\"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0mmetric_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetric_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# Add all metric names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0mmetrics_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_metrics_from_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m   3232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3233\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3234\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1af5e1883d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                   int) or self.epochs_since_last_save >= self.period:\n\u001b[1;32m   1010\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     if not self.model._in_multi_worker_mode(\n\u001b[1;32m   1054\u001b[0m     ) or multi_worker_util.should_save_checkpoint():\n\u001b[0;32m-> 1055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0;31m# If this is multi-worker training, and this worker should not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fine_tun = False\n",
    "\n",
    "for kfold_idx, (train_idxs, test_idxs) in enumerate(kfold.split(x, y[:, 0])): #left???\n",
    "\n",
    "    if kfold_idx ==4:\n",
    "        display.clear_output(wait=True)\n",
    "        print(f'K-Fold CV: {kfold_idx + 1:02d}/{kfold.n_splits:02d}')\n",
    "\n",
    "        # 1. Data\n",
    "        # ----------------------------------------\n",
    "\n",
    "    #------DEBUG--------:\n",
    "    #     print(test_idxs)     \n",
    "    #     print(np.unique(y[test_idxs, 0], return_counts=True))\n",
    "    #-------------------   \n",
    "\n",
    "        x_train = x[train_idxs]\n",
    "        y_train = y[train_idxs]\n",
    "        y_distance_train =y_distance[train_idxs]\n",
    "    #     label_df_train = label_df.iloc[train_idxs]\n",
    "\n",
    "        x_train, x_val, y_train, y_val, y_distance_train, y_distance_val = train_test_split(x_train, y_train, y_distance_train, test_size=0.2, \n",
    "                                                                                        random_state=42, stratify=y_train[:, 0])\n",
    "\n",
    "        x_test = x[test_idxs]\n",
    "        y_test = y[test_idxs]\n",
    "        y_distance_test =y_distance[test_idxs]\n",
    "    #     label_df_test = label_df.iloc[test_idxs]\n",
    "\n",
    "        #distance 누락!\n",
    "        x_train, y_train,y_train_onehot, y_train_distance = generate_data_by_patient(x_train, y_train, y_distance_train)\n",
    "        x_val, y_val, y_val_onehot, y_val_distance = generate_data_by_patient(x_val, y_val, y_distance_val)\n",
    "        x_test, y_test, y_test_onehot, y_test_distance = generate_data_by_patient(x_test, y_test, y_distance_test)\n",
    "\n",
    "        weight_for_m1 = (1 / len(y_train[y_train==-1]))*(len(y_train))/3.0 \n",
    "        weight_for_0 = (1 / len(y_train[y_train==0]))*(len(y_train))/3.0 \n",
    "        weight_for_1 = (1 / len(y_train[y_train==1]))*(len(y_train))/3.0\n",
    "\n",
    "        class_weight2=[weight_for_0,weight_for_1,weight_for_m1]\n",
    "        \n",
    "\n",
    "        # 2. Paths\n",
    "        # ----------------------------------------\n",
    "\n",
    "        output_path_kfold = os.path.join(output_path, f'kfold_{kfold_idx + 1:02d}/')\n",
    "        output_path_weight = os.path.join(output_path_kfold, r'weights/')\n",
    "\n",
    "        if os.path.isdir(output_path_weight)==False:\n",
    "            os.makedirs(output_path_weight)\n",
    "            \n",
    "      \n",
    "        \n",
    "        model = build_model()\n",
    "        model.save(os.path.join(output_path, r'model.hdf5'))\n",
    "\n",
    "        \n",
    "        model.compile(optimizer=optimizers.RMSprop(lr=1e-3),\n",
    "              loss={'regression_prediction':\"mae\",'classification':\"categorical_crossentropy\",'distance_prediction':\"mae\"},\n",
    "              loss_weights={'regression_prediction':1,'classification':1,'distance_prediction':loss_param},\n",
    "              metrics={'regression_prediction':\"mae\",'classification':\"acc\",'distance_prediction':\"mae\"})\n",
    "\n",
    "        print(len(model.trainable_weights))\n",
    "\n",
    "        # 4. Train the Model.\n",
    "        # ----------------------------------------\n",
    "\n",
    "        # Callbacks\n",
    "        checkpointer = callbacks.ModelCheckpoint(os.path.join(output_path_weight, 'weights_{epoch:08d}_{val_loss:.4g}.hdf5'),\n",
    "                                                 save_weights_only=True)\n",
    "        csv_logger = callbacks.CSVLogger(os.path.join(output_path_kfold, r'log.csv'), append=True)\n",
    "        learning_sch = callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "        # Training batch size 16 -> 8\n",
    "        model.fit(x_train,{'regression_prediction':y_train, 'classification':y_train_onehot,'distance_prediction':y_train_distance},\n",
    "                  batch_size=16,\n",
    "                  epochs=50,\n",
    "                  validation_data=(x_val, {'regression_prediction':y_val,'classification':y_val_onehot,'distance_prediction':y_val_distance}),\n",
    "                  callbacks=[checkpointer, csv_logger],\n",
    "                  initial_epoch=0,\n",
    "                  verbose=1)\n",
    "\n",
    "        K.clear_session()\n",
    "        del model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = label_df.copy()\n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.iloc[[0,3,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "predictions_kfold = []\n",
    "labels_kfold = []\n",
    "distance_regression = [] \n",
    "\n",
    "total_info =[]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# model_parm_name=\"D\"+depth+\"_\"+dropout_rat\n",
    "\n",
    "for kfold_idx, (train_idxs, test_idxs) in enumerate(kfold.split(x, y[:, 0])):\n",
    "    print(f'K-Fold CV: {kfold_idx + 1:02d}/{kfold.n_splits:02d}')\n",
    "    \n",
    "    # 1. Data\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    if kfold_idx==0:\n",
    "\n",
    "        x_test = x[test_idxs]\n",
    "        y_test = y[test_idxs]\n",
    "\n",
    "        label_df_test = label_df.iloc[test_idxs]\n",
    "\n",
    "        x_test, y_test, y_test_onehot = generate_data_by_patient(x_test, y_test)\n",
    "\n",
    "        # 2. Paths\n",
    "        # ----------------------------------------\n",
    "\n",
    "    #     output_path_kfold = os.path.join(output_path, model_parm_name, f'kfold_{kfold_idx + 1:02d}/')\n",
    "        output_path_kfold = os.path.join(output_path,  f'kfold_{kfold_idx + 1:02d}/')\n",
    "        output_path_weight = os.path.join(output_path_kfold, r'weights/')\n",
    "\n",
    "        # 3. Plot Learning Curves.\n",
    "        # ----------------------------------------\n",
    "\n",
    "        # log 저장: loss, mae, val_loss, val_mae\n",
    "        log_df = pd.read_csv(os.path.join(output_path_kfold, r'log.csv'))\n",
    "\n",
    "\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        plt.figure(figsize=(25, 6))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title(f'Learning Curves ({kfold_idx + 1:02d}/{kfold.n_splits:02d})')\n",
    "        plt.plot(log_df.loss)\n",
    "        plt.plot(log_df.val_loss)\n",
    "        plt.legend(('Train Loss', 'Validation Loss'))\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.plot(log_df.classification_acc)\n",
    "        plt.plot(log_df.val_classification_acc)\n",
    "        plt.ylim(0, 1.5)\n",
    "        plt.legend(('Train Classification MAE', 'Validation Classification MAE'))\n",
    "\n",
    "#         plt.subplot(2,2,3)\n",
    "#         plt.plot(log_df.distance_prediction_mae)\n",
    "#         plt.plot(log_df.val_distance_prediction_mae)\n",
    "#         plt.ylim(0, 1.5)\n",
    "#         plt.legend(('Train distance Classification MAE', 'Validation distance Classification MAE'))\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.plot(log_df.regression_prediction_mae)\n",
    "        plt.plot(log_df.val_regression_prediction_mae)\n",
    "        plt.ylim(0, 1.5)\n",
    "        plt.legend(('Train regression Classification MAE', 'Validation regression Classification MAE'))\n",
    "\n",
    "        plt.show()\n",
    "        plt.style.use('seaborn-white')\n",
    "        print(f'Min. validation loss epoch: {log_df.val_loss.idxmin() + 1}')\n",
    "        print(f'Max. Classification MAE epoch: {log_df.val_classification_acc.idxmax() + 1}')\n",
    "#         print(f'Max. distance validation MAE epoch: {log_df.val_distance_prediction_mae.idxmax() + 1}')\n",
    "        print(f'Max. regression validation MAE epoch: {log_df.val_regression_prediction_mae.idxmax() + 1}')\n",
    "\n",
    "\n",
    "\n",
    "        info_df = label_df.copy()\n",
    "\n",
    "        result_info_df = info_df.iloc[test_idxs]\n",
    "\n",
    "        inference_df = result_info_df.copy()\n",
    "\n",
    "        # 4. Load a Model.\n",
    "        # ----------------------------------------\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        #sgcwhb/Malocclusion/results/prototype_regression_so_img/so_rl/model.hdf5\n",
    "        model = models.load_model(os.path.join(output_path, r'model.hdf5'))\n",
    "        #validation mae가 가장 적은 model weight load\n",
    "        model.load_weights(glob.glob(os.path.join(output_path_weight, f'weights_{log_df.val_loss.idxmin() + 1:08d}*.hdf5'))[0])\n",
    "\n",
    "        # 5. Display\n",
    "        # ----------------------------------------\n",
    "\n",
    "\n",
    "        prediction = model.predict(x_test)\n",
    "\n",
    "        prediction_distance_r = prediction[0][:int(prediction[0].shape[0]/2),0] #Right\n",
    "        prediction_distance_l = prediction[0][int(prediction[0].shape[0]/2):,0] #left\n",
    "\n",
    "        r = prediction_distance_r.copy()\n",
    "        l = prediction_distance_l.copy()\n",
    "\n",
    "        #-1~1사이 score\n",
    "        r = np.round(r) #반올림\n",
    "        r[r<-1]= -1\n",
    "        r[r>1] = 1\n",
    "\n",
    "\n",
    "        l = np.round(l)\n",
    "        l[l<-1]= -1\n",
    "        l[l>1] = 1    \n",
    "\n",
    "    #     print(l.shape)\n",
    "    #     print(r.shape)\n",
    "    #     print(info_df.shape)\n",
    "    #     print(result_info_df.shape)\n",
    "\n",
    "        inference_df['prediction_class_r'] = r\n",
    "        inference_df['prediction_class_l'] =l\n",
    "        inference_df['regression_distance_r'] = np.round(prediction_distance_r,3)\n",
    "        inference_df['regression_distance_l'] = np.round(prediction_distance_l,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        inference_df.to_csv(os.path.join(output_path_kfold, r'info.csv'))\n",
    "        total_info.append(inference_df)\n",
    "\n",
    "    total_df = pd.concat(total_info)\n",
    "    total_df.to_csv(os.path.join(output_path,'total.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "predictions_kfold = []\n",
    "labels_kfold = []\n",
    "distance_regression = [] \n",
    "\n",
    "total_info =[]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# model_parm_name=\"D\"+depth+\"_\"+dropout_rat\n",
    "\n",
    "for kfold_idx, (train_idxs, test_idxs) in enumerate(kfold.split(x, y[:, 0])):\n",
    "    \n",
    "    log_df = pd.read_csv(os.path.join(output_path_kfold, r'log.csv'))\n",
    "    \n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title(f'Learning Curves ({kfold_idx + 1:02d}/{kfold.n_splits:02d})')\n",
    "    plt.plot(log_df.loss)\n",
    "    plt.plot(log_df.val_loss)\n",
    "    plt.legend(('Train Loss', 'Validation Loss'))\n",
    "    \n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(log_df.classification_acc)\n",
    "    plt.plot(log_df.val_classification_acc)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend(('Train Classification acc', 'Validation Classification acc'))\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(log_df.distance_prediction_acc)\n",
    "    plt.plot(log_df.val_distance_prediction_acc)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend(('Train distance Classification acc', 'Validation distance Classification acc'))\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(log_df.regression_prediction_acc)\n",
    "    plt.plot(log_df.val_regression_prediction_acc)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend(('Train regression Classification acc', 'Validation regression Classification acc'))\n",
    "\n",
    "    plt.show()\n",
    "    plt.style.use('seaborn-white')\n",
    "    print(f'Min. validation loss epoch: {log_df.val_loss.idxmin() + 1}')\n",
    "    print(f'Min. Classification MAE epoch: {log_df.val_classification_acc.idxmin() + 1}')\n",
    "    print(f'Min. distance validation MAE epoch: {log_df.val_distance_prediction_acc.idxmin() + 1}')\n",
    "    print(f'Min. regression validation MAE epoch: {log_df.val_regression_prediction_acc.idxmin() + 1}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    info_df = label_df.copy()\n",
    "    \n",
    "    result_info_df = info_df.iloc[test_idxs]\n",
    "    \n",
    "    inference_df = result_info_df.copy()\n",
    "    \n",
    "    # 4. Load a Model.\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.val_classification_acc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_results_df = pd.DataFrame(metrics, columns=('test_loss', 'test_mae'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_df['angle_class_r'].append(total_df['angle_class_l'])\n",
    "prediction =  total_df['prediction_class_r'].append(total_df['prediction_class_l'])\n",
    "data = np.array(data)\n",
    "prediction=np.array(prediction,dtype = int)\n",
    "\n",
    "cm = confusion_matrix(data, prediction, labels=[-1, 0, 1])\n",
    "\n",
    "print(cm)\n",
    "print(\"\")\n",
    "print(f'Accuracy: {(cm[0, 0] + cm[1, 1] + cm[2, 2]) / cm.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
